{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import logging\n",
    "import time\n",
    "sys.path.append('..')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import string\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dir = '/Users/isaachenrion/x/research/'\n",
    "\n",
    "local_dir = os.path.join(research_dir, 'graphs')\n",
    "remote_dir = os.path.join(research_dir, 'remote')\n",
    "root_dir = local_dir\n",
    "\n",
    "root_data_dir = os.path.join(root_dir, 'data/proteins')\n",
    "casp11 = os.path.join(root_data_dir, 'casp11')\n",
    "pdb25 = os.path.join(root_data_dir, 'pdb25')\n",
    "\n",
    "data_dir = pdb25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pdbs from the PDB website using the id lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdbs(id_list_filename, savedir):\n",
    "    \n",
    "    with open(id_list_filename, 'r') as f:\n",
    "        ids = f.read().split(',')\n",
    "        \n",
    "    prefix = 'https://files.rcsb.org/view'\n",
    "    suffix = '.pdb'\n",
    "    \n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    \n",
    "    for i, id in enumerate(ids):\n",
    "        pdb_id = id[:-1] + suffix\n",
    "        url = os.path.join(prefix, pdb_id)\n",
    "        path_name = os.path.join(savedir, pdb_id)\n",
    "        urllib.request.urlretrieve(url, path_name)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ['test', 'train', 'valid']\n",
    "pdbs = os.path.join(data_dir, 'pdbs')\n",
    "id_dir = 'id_lists'\n",
    "for mode in modes:\n",
    "    download_pdbs(os.path.join(id_dir, mode + '.txt'), pdbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for converting BioPDB structures into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio.Alphabet import ThreeLetterProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_atom(residue):\n",
    "    '''Get the atom from a residue that is relevant for measuring residue-residue distances.\n",
    "    In all amino acids this is CB, except for glycine where it is CA. If neither of these\n",
    "    is present, return None'''\n",
    "    if residue.get_resname().upper() == 'GLY':\n",
    "        atom_id = 'CA'\n",
    "    else:\n",
    "        atom_id = 'CB'\n",
    "    try:\n",
    "        atom = residue[atom_id]\n",
    "    except KeyError:\n",
    "        atom = None\n",
    "    return atom\n",
    "\n",
    "def relevant_chain(structure, chain_id):\n",
    "    '''Given a structure and a chain id, return that chain from the structure. \n",
    "    This is robust to upper and lower case.'''\n",
    "    model = structure[0]\n",
    "    try:\n",
    "        chain = model[chain_id.upper()]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            chain = model[chain_id.lower()]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Structure {} has no chain {}. It only has {}\".format(structure.get_id(), chain_id, list(structure.get_chains())))\n",
    "    return chain\n",
    "\n",
    "def get_seq_and_coords(structure, chain_id, alphabet, distances=False):\n",
    "    '''Given a structure and chain id, return the sequence as a one-hot numpy\n",
    "    array, and the coordinates of the residues as a numpy array. \n",
    "    Optionally, return the matrix of distances between the residues.'''\n",
    "    chain = relevant_chain(structure, chain_id)\n",
    "    \n",
    "    residues = list(chain.get_residues())\n",
    "    residues = [r for r in residues if r.get_resname() in alphabet]\n",
    "    \n",
    "    # sequence\n",
    "    sequence = [r.get_resname() for r in residues]\n",
    "    seq_vec = _string_vectorizer(sequence, alphabet)\n",
    "    if not np.all(seq_vec.sum(1) == 1):\n",
    "        bad_indices = np.where(seq_vec.sum(1) != 1)[0]\n",
    "        bad_residues = [r.get_resname() for i, r in enumerate(residues) if i in bad_indices]\n",
    "        out_str = \"Sequence {}/{} has not been correctly one-hot encoded.\\n\".format(pdb_id, chain_id)\n",
    "        out_str += \"Indices {} in the sequence were incorrectly encoded\\n\".format(', '.join(bad_indices))\n",
    "        our_str += \"These correspond to the following residues: {}\".format(', '.join(bad_residues))\n",
    "        raise ValueError(out_str)\n",
    "    \n",
    "    # coords\n",
    "    coords = np.zeros((len(residues), 3))\n",
    "    for i, r1 in enumerate(residues):\n",
    "        a1 = relevant_atom(r1)\n",
    "        if a1 is not None:\n",
    "            xyz = a1.get_coord()\n",
    "            coords[i] = xyz\n",
    "        else:\n",
    "            coords[i] = [np.inf, np.inf, np.inf]\n",
    "    \n",
    "    # distances\n",
    "    if distances:\n",
    "        dists = np.zeros((len(residues), len(residues)))\n",
    "        for i, r1 in enumerate(residues):\n",
    "            a1 = relevant_atom(r1)\n",
    "            for j, r2 in enumerate(residues):\n",
    "                a2 = relevant_atom(r2)\n",
    "                if a1 is not None and a2 is not None:\n",
    "                    dists[i, j] = a1 - a2\n",
    "                else:\n",
    "                    dists[i, j] = np.inf\n",
    "        return seq_vec, coords, dists\n",
    "    return seq_vec, coords\n",
    "            \n",
    "def _string_vectorizer(strng, alphabet=string.ascii_uppercase):\n",
    "    '''Given a string and alphabet, return a one-hot representation as a numpy array'''\n",
    "    vector = np.array([[0 if char != letter else 1 for char in alphabet]\n",
    "                  for letter in strng])\n",
    "    return vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing function for a directory of pdb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pdb_directory(pdb_directory, id_list_filename, file_format, n=None):\n",
    "    '''Preprocess all of the pdb files in a directory that correspond to named ids in \n",
    "    a given id list. '''\n",
    "    t = time.time()\n",
    "    parent_dir, child_dir = os.path.split(pdb_directory)\n",
    "    with open(id_list_filename, 'r') as f:\n",
    "        ids = f.read().split(',')\n",
    "                \n",
    "    if file_format == 'pdb':\n",
    "        parser = PDBParser()\n",
    "    elif file_format == 'cif':\n",
    "        parser = MMCIFParser()\n",
    "    \n",
    "    alphabet = [sym.upper() for sym in ThreeLetterProtein().letters]\n",
    "    sequences = []\n",
    "    coords = []\n",
    "    \n",
    "    for i, id in enumerate(ids):\n",
    "            \n",
    "        pdb_id = id[:-1]\n",
    "        chain_id = id[-1]\n",
    "        pdb_filename = pdb_id + '.' + file_format\n",
    "        \n",
    "        path_to_pdb = os.path.join(pdb_directory, pdb_filename)\n",
    "        structure = parser.get_structure(pdb_id, path_to_pdb)\n",
    "        \n",
    "        seq_vec, coord = get_seq_and_coords(structure, chain_id, alphabet)\n",
    "        \n",
    "        sequences.append(seq_vec)\n",
    "        coords.append(coord)\n",
    "        \n",
    "        if i > 0 and i % 500 == 0:\n",
    "            logging.info(\"Preprocessed {} proteins\".format(i))\n",
    "        if n is not None and i == n - 1:\n",
    "            break\n",
    "    \n",
    "    savedir = os.path.join(data_dir, 'preprocessed')\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    save_filename = os.path.join(savedir, os.path.split(pdb_directory)[1] + '.pkl')\n",
    "    logging.info(\"Preprocessed {} proteins in {:.1f} seconds\".format(len(sequences), time.time() - t))\n",
    "    with open(save_filename, 'wb') as f:\n",
    "        pickle.dump(dict(sequences=sequences,coords=coords), f)\n",
    "        \n",
    "    return None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run preprocessing over the pdb directories we have downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ['test', 'train', 'valid']\n",
    "for mode in modes:\n",
    "    preprocess_pdb_directory(os.path.join(pdbs, mode), os.path.join(id_dir, mode + '.txt'), 'pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
